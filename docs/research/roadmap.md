!!! note "Compilation of categorized learning resources"
    **Cachekit** resources recommended by [Jing Liu](https://jing-liu.com/)

    + [vllm](https://github.com/vllm-project/vllm)

    + [Nvidia Inference Optimization blog](https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization)

    + [Yao Fu](https://www.notion.so/yaofu/Towards-100x-Speedup-Full-Stack-Transformer-Inference-Optimization-43124c3688e14cffaf2f1d6cbdf26c6c)

    + [Yao Fu 2](https://yaofu.notion.site/Full-Stack-Transformer-Inference-Optimization-Season-2-Deploying-Long-Context-Models-ee25d3a77ba14f73b8ae19147f77d5e2)

    -------

    **Flash Attention**

    + [Flash Attention](https://github.com/Dao-AILab/flash-attention)

    -------
    
    **Sparse Attention** resources recommended by [Yefei He](http://hexy.tech/)

    + [MInference](https://arxiv.org/abs/2407.02490)

    + cross attention: online blogs will just be ok

    -------

    **Diffusion model** resources recommended by [bohan](https://bohanzhuang.github.io/)

    + [Diffusion models](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)

    + [Generative models](https://yang-song.net/blog/2021/score/)

    -------

    **Vision transformer**

    + ViT

    + CNN(ResNet)

    -------
    
    **Multimodal LLM**

    + [LLaVA](https://github.com/haotian-liu/LLaVA)

    + [NExT-GPT](https://github.com/NExT-GPT/NExT-GPT)
    
    -------

    **Attention** Basics

    + [sebastian](https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention)

    -------

    **Relevant Online Courses** 

    + [cs231n](https://cs231n.github.io/)

    + [HanLAB TinyML](https://hanlab.mit.edu/courses/2024-fall-65940)

    + [CMU dlsys](https://dlsyscourse.org/)

    + [Parallel Computing](https://gfxcourses.stanford.edu/cs149/fall21/)

!!! note "HuggingFace resources"
    + [transformer tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer)



!!! note "General videos"
    [Terence Tao at IMO 2024](https://www.youtube.com/watch?v=e049IoFBnLA)

    [Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE&t=5954s)




