# 2024.11.10
## 本周进度

1. VLM paper阅读
   
   + Medusa: Simple Framework for Accelerating LLM Generation with Multiple Decoding Heads
   
   + Accelerating Large Language Model Decoding with Speculative Sampling
   
   + 几篇关于auto-regressive generation的blog（忘记网址了）

2. 实战

   + 利用vllm profiler对vllm的性能进行测试

## 下周规划

1. MIT6.5940学习：lec5-6；lab看情况
2. video generation论文阅读
   
   + [CLLM](https://arxiv.org/pdf/2403.00835)
   
   + [TRAINING-FREE SPECULATIVE JACOBI DECODING](https://arxiv.org/pdf/2410.01699)

3. 重温[A Survey on Multimodal Large Language Models](https://arxiv.org/abs/2306.13549)，跑一些典型模型的base code，如llava/Qwen-vl
4. 学习vllm/flashAttention的idea和code，测试性能
5. cs231n和pytorch basic收尾
6. 熟悉DiT/ViT架构

------

# 2024.11.17
## 本周进度

+ 完成mit6.5940的lec3-4学习
+ 完成cs231n的module2
+ 重温[A Survey on Multimodal Large Language Models](https://arxiv.org/abs/2306.13549)

## 下周规划

1. MIT6.5940学习：lec5-6；lab看情况
2. video generation论文阅读（顺延）

  + [CLLM](https://arxiv.org/pdf/2403.00835)
  
  + [TRAINING-FREE SPECULATIVE JACOBI DECODING](https://arxiv.org/pdf/2410.01699)

3. 跑一些典型模型的base code，如llava/Qwen-vl（顺延）
4. 学习vllm/flashAttention的idea和code，测试性能（顺延）
5. cs231n和pytorch basic收尾（顺延）
6. 熟悉DiT/ViT架构，阅读（顺延）

   + [Diffusion models](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)

   + [Generative models](https://yang-song.net/blog/2021/score/)

# 2024.11.24
## 本周进度

1. mit6.5940 lec5-6学习

2. llava源码阅读和运行

3. 正在阅读diffusion model的架构

## 下周规划

1. [6.S978 Deep Generative Models](https://mit-6s978.github.io/)论文阅读；[lilian wen](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#nice)的diffusion数学原理理解；DiT、ViT跑代码

2. [MIT 6.5940](https://hanlab.mit.edu/courses/2024-fall-65940)

3. 熟悉kvcache的原理和压缩方法。[minicache](https://arxiv.org/abs/2405.14366)阅读，代码运行

4. tokenizer、encoder、decoder代码搭建 (transformer整体pipeline搭建)

5. [llmscratch](LLMs-from-scratch)学习fine-tune、pre-train