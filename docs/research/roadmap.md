# 2024.11.10
## 本周进度

1. VLM paper阅读
   + Medusa: Simple Framework for Accelerating LLM Generation with Multiple Decoding Heads
   + Accelerating Large Language Model Decoding with Speculative Sampling
   + 几篇关于auto-regressive generation的blog（忘记网址了）
2. 实战
   + 利用vllm profiler对vllm的性能进行测试

## 下周规划

1. MIT6.5940学习：lec5-6；lab看情况
2. 重温[A Survey on Multimodal Large Language Models](https://arxiv.org/abs/2306.13549)，跑一些典型模型的base code，如llava/Qwen-vl
3. 学习vllm/flashAttention的idea和code，测试性能
4. cs231n和pytorch basic收尾
5. 熟悉DiT/ViT架构